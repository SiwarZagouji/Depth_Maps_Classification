{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9875e5ff",
   "metadata": {},
   "source": [
    "## <center> CNN applied on RGBD images </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b8340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage import zoom\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd40f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total indoor images: 829\n",
      "Total indoor depth maps: 829\n",
      "Total outdoor images: 834\n",
      "Total outdoor depth maps: 834\n"
     ]
    }
   ],
   "source": [
    "data_dir = r'C:\\Users\\Siwar\\Downloads\\data'  \n",
    "indoor_dir = os.path.join(data_dir, 'indoors')  # Path to the indoor images and depth maps folder\n",
    "outdoor_dir = os.path.join(data_dir, 'outdoors')  # Path to the outdoor images and depth maps folder\n",
    "\n",
    "# Function to read and process the images and depth maps\n",
    "def read_data(directory):\n",
    "    images = []\n",
    "    depth_maps = []\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if filename.endswith('.png'):\n",
    "            img = Image.open(file_path)  \n",
    "            images.append(img)\n",
    "        elif filename.endswith('.npy'):\n",
    "            depth_map = np.load(file_path)  \n",
    "            depth_maps.append(depth_map)\n",
    "    return images, depth_maps\n",
    "\n",
    "# Read indoor images and depth maps\n",
    "indoor_images, indoor_depth_maps = read_data(indoor_dir)\n",
    "print(f\"Total indoor images: {len(indoor_images)}\")\n",
    "print(f\"Total indoor depth maps: {len(indoor_depth_maps)}\")\n",
    "\n",
    "# Read outdoor images and depth maps\n",
    "outdoor_images, outdoor_depth_maps = read_data(outdoor_dir)\n",
    "print(f\"Total outdoor images: {len(outdoor_images)}\")\n",
    "print(f\"Total outdoor depth maps: {len(outdoor_depth_maps)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a14c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize indoor images\n",
    "resized_indoor_images = []\n",
    "for image in indoor_images:\n",
    "    resized_image = image.resize((64, 48))\n",
    "    resized_indoor_images.append(resized_image)\n",
    "\n",
    "# Resize outdoor images\n",
    "resized_outdoor_images = []\n",
    "for image in outdoor_images:\n",
    "    resized_image = image.resize((64, 48))\n",
    "    resized_outdoor_images.append(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240b74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize indoor depth maps\n",
    "resized_indoor_depth_maps = []\n",
    "for depth_map in indoor_depth_maps:\n",
    "    depth_map = depth_map.astype(np.uint8)\n",
    "    resized_depth_map = zoom(depth_map, (1/16, 1/16, 1), order=1)\n",
    "    resized_depth_map = resized_depth_map.astype(np.uint8)\n",
    "    resized_indoor_depth_maps.append(resized_depth_map)\n",
    "\n",
    "# Resize outdoor depth maps\n",
    "resized_outdoor_depth_maps = []\n",
    "for depth_map in outdoor_depth_maps:\n",
    "    depth_map = depth_map.astype(np.uint8)\n",
    "    resized_depth_map = zoom(depth_map, (1/16, 1/16, 1), order=1)\n",
    "    resized_depth_map = resized_depth_map.astype(np.uint8)\n",
    "    resized_outdoor_depth_maps.append(resized_depth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3155268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert resized RGB images to TensorFlow tensors\n",
    "indoor_rgb_images_tensor = tf.stack([tf.image.convert_image_dtype(image, tf.float32) for image in resized_indoor_images])\n",
    "outdoor_rgb_images_tensor = tf.stack([tf.image.convert_image_dtype(image, tf.float32) for image in resized_outdoor_images])\n",
    "\n",
    "# Convert resized depth maps to TensorFlow tensors\n",
    "indoor_depth_maps_tensor = tf.stack([tf.image.convert_image_dtype(depth_map, tf.float32) for depth_map in resized_indoor_depth_maps])\n",
    "outdoor_depth_maps_tensor = tf.stack([tf.image.convert_image_dtype(depth_map, tf.float32) for depth_map in resized_outdoor_depth_maps])\n",
    "\n",
    "# Concatenate RGB images and depth maps along the channel axis (axis=3) to create RGBD images\n",
    "indoor_rgbd_images_tensor = tf.concat([indoor_rgb_images_tensor, indoor_depth_maps_tensor], axis=3)\n",
    "outdoor_rgbd_images_tensor = tf.concat([outdoor_rgb_images_tensor, outdoor_depth_maps_tensor], axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d77eff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(829, 834)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indoor_rgbd_images_tensor), len(outdoor_rgbd_images_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6243bf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([48, 64, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indoor_rgbd_images_tensor[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff57300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indoor_rgbd_images_numpy = indoor_rgbd_images_tensor.numpy()\n",
    "outdoor_rgbd_images_numpy = outdoor_rgbd_images_tensor.numpy()\n",
    "\n",
    "# Split indoor RGBD images into train, validation and test sets\n",
    "indoor_train_rgbd, indoor_test_rgbd = train_test_split(indoor_rgbd_images_numpy, test_size=0.2, random_state=43)\n",
    "indoor_train_rgbd, indoor_val_rgbd = train_test_split(indoor_train_rgbd, test_size=0.2, random_state=43)\n",
    "# Split outdoor RGBD images into train, validation and test sets\n",
    "outdoor_train_rgbd, outdoor_test_rgbd = train_test_split(outdoor_rgbd_images_numpy, test_size=0.2, random_state=43)\n",
    "outdoor_train_rgbd, outdoor_val_rgbd = train_test_split(outdoor_train_rgbd, test_size=0.1, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "530c9e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 133, 166, 600, 67, 167)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indoor_train_rgbd),len(indoor_val_rgbd),len(indoor_test_rgbd), len(outdoor_train_rgbd),len(outdoor_val_rgbd),len(outdoor_test_rgbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd328817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1130, 200, 333)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, validation and test data\n",
    "train_data=np.concatenate((indoor_train_rgbd, outdoor_train_rgbd), axis=0)\n",
    "val_data=np.concatenate((indoor_val_rgbd, outdoor_val_rgbd), axis=0)\n",
    "test_data=np.concatenate((indoor_test_rgbd, outdoor_test_rgbd), axis=0)\n",
    "train_labels = np.concatenate((np.zeros(len(indoor_train_rgbd)), np.ones(len(outdoor_train_rgbd))))\n",
    "test_labels = np.concatenate((np.zeros(len(indoor_test_rgbd)), np.ones(len(outdoor_test_rgbd))))\n",
    "val_labels = np.concatenate((np.zeros(len(indoor_val_rgbd)), np.ones(len(outdoor_val_rgbd))))\n",
    "len(train_data),len(val_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd917b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)\n",
    "tf.random.set_seed(43)\n",
    "# the model architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(48, 64, 4), kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ded287d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "36/36 [==============================] - 18s 113ms/step - loss: 3.1766 - accuracy: 0.8088 - val_loss: 3.5502 - val_accuracy: 0.6650\n",
      "Epoch 2/30\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 2.5751 - accuracy: 0.8628 - val_loss: 3.4262 - val_accuracy: 0.6650\n",
      "Epoch 3/30\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 2.1262 - accuracy: 0.9044 - val_loss: 3.0510 - val_accuracy: 0.6650\n",
      "Epoch 4/30\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 1.8249 - accuracy: 0.9221 - val_loss: 2.8001 - val_accuracy: 0.6650\n",
      "Epoch 5/30\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 1.5585 - accuracy: 0.9230 - val_loss: 2.4563 - val_accuracy: 0.6650\n",
      "Epoch 6/30\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 1.3533 - accuracy: 0.9310 - val_loss: 2.2682 - val_accuracy: 0.6650\n",
      "Epoch 7/30\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 1.1927 - accuracy: 0.9434 - val_loss: 1.8584 - val_accuracy: 0.6700\n",
      "Epoch 8/30\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 1.0359 - accuracy: 0.9469 - val_loss: 1.6222 - val_accuracy: 0.6700\n",
      "Epoch 9/30\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.9170 - accuracy: 0.9513 - val_loss: 1.3523 - val_accuracy: 0.6900\n",
      "Epoch 10/30\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.8051 - accuracy: 0.9646 - val_loss: 1.2872 - val_accuracy: 0.7350\n",
      "Epoch 11/30\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.7490 - accuracy: 0.9549 - val_loss: 1.0676 - val_accuracy: 0.7400\n",
      "Epoch 12/30\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.7257 - accuracy: 0.9407 - val_loss: 1.1803 - val_accuracy: 0.7200\n",
      "Epoch 13/30\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.7069 - accuracy: 0.9354 - val_loss: 1.0639 - val_accuracy: 0.7550\n",
      "Epoch 14/30\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.6594 - accuracy: 0.9469 - val_loss: 0.6683 - val_accuracy: 0.9300\n",
      "Epoch 15/30\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.5835 - accuracy: 0.9566 - val_loss: 0.6867 - val_accuracy: 0.8750\n",
      "Epoch 16/30\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.5391 - accuracy: 0.9566 - val_loss: 0.6543 - val_accuracy: 0.8950\n",
      "Epoch 17/30\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.4919 - accuracy: 0.9699 - val_loss: 0.5555 - val_accuracy: 0.9300\n",
      "Epoch 18/30\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.4230 - accuracy: 0.9823 - val_loss: 0.4724 - val_accuracy: 0.9450\n",
      "Epoch 19/30\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.4574 - accuracy: 0.9540 - val_loss: 0.5506 - val_accuracy: 0.9100\n",
      "Epoch 20/30\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.4481 - accuracy: 0.9655 - val_loss: 0.5776 - val_accuracy: 0.9050\n",
      "Epoch 21/30\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.4036 - accuracy: 0.9735 - val_loss: 0.5990 - val_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.4202 - accuracy: 0.9602 - val_loss: 0.3850 - val_accuracy: 0.9700\n",
      "Epoch 23/30\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.3762 - accuracy: 0.9752 - val_loss: 0.5312 - val_accuracy: 0.8950\n",
      "Epoch 24/30\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.3464 - accuracy: 0.9770 - val_loss: 0.3410 - val_accuracy: 0.9600\n",
      "Epoch 25/30\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.3365 - accuracy: 0.9690 - val_loss: 0.9742 - val_accuracy: 0.7400\n",
      "Epoch 26/30\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.3326 - accuracy: 0.9743 - val_loss: 0.9442 - val_accuracy: 0.8100\n",
      "Epoch 27/30\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.3292 - accuracy: 0.9708 - val_loss: 0.5549 - val_accuracy: 0.8950\n",
      "Epoch 28/30\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.2850 - accuracy: 0.9885 - val_loss: 0.3142 - val_accuracy: 0.9550\n",
      "Epoch 29/30\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.2909 - accuracy: 0.9788 - val_loss: 0.4328 - val_accuracy: 0.9200\n",
      "Epoch 30/30\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.3387 - accuracy: 0.9664 - val_loss: 0.3362 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277aa347580>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs=30, batch_size=32, validation_data=(val_data, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90536309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f168a868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2878 - accuracy: 0.9832\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3362 - accuracy: 0.9600\n",
      "Train Accuracy: 0.98\n",
      "Validation Accuracy: 0.96\n",
      "train_loss: 0.29\n",
      "val_loss: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on train data\n",
    "train_loss, train_accuracy = model.evaluate(train_data, train_labels)\n",
    "\n",
    "# Calculate accuracy on validation data\n",
    "val_loss, val_accuracy = model.evaluate(val_data, val_labels)\n",
    "\n",
    "print(\"Train Accuracy:\", round(train_accuracy,2))\n",
    "print(\"Validation Accuracy:\", round(val_accuracy,2))\n",
    "print(\"train_loss:\",round(train_loss,2))\n",
    "print(\"val_loss:\",round(train_loss,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb54e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Precision: 0.91\n",
      "Recall: 0.99\n",
      "F1 Score: 0.95\n",
      "AUC-ROC Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "precision = precision_score(test_labels, predicted_labels)\n",
    "recall = recall_score(test_labels, predicted_labels)\n",
    "f1 = f1_score(test_labels, predicted_labels)\n",
    "auc_roc = roc_auc_score(test_labels, predictions)\n",
    "print(\"Accuracy:\", round(accuracy, 2))\n",
    "print(\"Precision:\", round(precision, 2))\n",
    "print(\"Recall:\", round(recall, 2))\n",
    "print(\"F1 Score:\", round(f1, 2))\n",
    "print(\"AUC-ROC Score:\", round(auc_roc, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcceb366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2339d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
